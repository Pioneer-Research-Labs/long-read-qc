
// Set the following when running locally on your laptop so that S3 downloads and other AWS services are allowed.//
 //aws.profile = 'general-116981805068'
// --- Default parameters
params.preprocess_genome_tags = false
// Running it
params.cores = 4

// Sequencing technology
params.tech =  "map-ont"

// map all reads to genome boolean
params.map_genome = false

// sample sheet
params.samplesheet = "samplesheet.csv"

// tesseract sample sheet
params.tesseract_samplesheet = "tesseract_samplesheet.csv"


// The output directory names are a concatenation of timestamp and the sample sheet name.
// A flag to toggle where the output resides in the prod or dev parent directory, by default it is prod.
params{
    s3_path = "s3://pioneer-analysis/long_read_qc/"
    parentdir = "dev"
    outdir = "s3://pioneer-analysis/long_read_qc/" + params.parentdir + "/" + new java.util.Date().format("yyyy_MM_dd_HH_mm_ss") + "_" + new File(params.samplesheet).getName().split(".csv")[0]
    }

// genomes directory
params.genomes = "s3://pioneer-data/genomes/"

// constructs directory
params.constructs = "s3://pioneer-sequencing/constructs/"

// Tesseract oligo file
params.tesseract_oligo_file = "assets/Tesseract_Barcode_Tracking_Grid.csv"

// barcode searching parameters
params.error_rate = 0.1
params.min_overlap = 3

// barcode searching parameters
params.min_bc_len = 20
params.max_bc_len = 60

// metagenomic parameters
params.sourmash_db = "/srv/shared/databases/sourmash/gtdb-rs220-k21.zip"
params.meta_ovlp = 1000
params.taxonomy = "/srv/shared/databases/sourmash/gtdb-rs220.lineages.sqldb"

params.help = false
params.path_prefix = "" // Empty string means local file system
params.aws_batch = false

// -- Ensure sample sheet validation checks for unique sample ids
params.validationSkipDuplicateCheck = false

// --- Pipeline config

manifest.defaultBranch = 'main'

plugins {
    id 'nf-schema@2.0.0'
    }

docker {
    enabled = true
    runOptions = '--pull=always'
}

profiles {
    standard {
        process.executor = 'local'
        process.container = "116981805068.dkr.ecr.us-west-1.amazonaws.com/pioneer/pipelines:long-read-qc"
        cleanup = true
    }

    awsbatch {
        process.executor = 'awsbatch'
        process.queue = 'nextflow-batch'
        process.container = "116981805068.dkr.ecr.us-west-1.amazonaws.com/pioneer/pipelines:long-read-qc"
        aws.client.maxConnections = 20
        aws.client.connectionTimeout = 10000
        aws.region = 'us-west-1'
        aws.batch.cliPath = '/home/ec2-user/miniconda/bin/aws'
        aws.batch.delayBetweenAttempts = 30
        workDir = "s3://pioneer-scratch/nextflow_scratch/"
        process.memory = "18 GB"
	    params.path_prefix = "s3:/"
	    params.aws_batch = true
	}
}
